{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from types import ModuleType\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "c = ModuleType(\"contstants\")\n",
    "# ------------------------------------- Constants -------------------------------------\n",
    "c.Classes = 0\n",
    "c.Training_Data = 1\n",
    "c.Testing_Data = 2\n",
    "c.Model = 3\n",
    "c.Client_Accuracies = 4\n",
    "c.Client_Performance_Scores = 5\n",
    "c.Current_Performance_Score = 6\n",
    "c.Client_Age = 7\n",
    "\n",
    "NUM_CLIENTS = 10\n",
    "\n",
    "\"\"\"\n",
    "+---------------------------------------------------------------------------------+\n",
    "|    ____ ___ _____ _    ____       _  ___    ____        _                 _     |\n",
    "|   / ___|_ _|  ___/ \\  |  _ \\     / |/ _ \\  |  _ \\  __ _| |_ __ _ ___  ___| |_   |\n",
    "|  | |    | || |_ / _ \\ | |_) |____| | | | | | | | |/ _` | __/ _` / __|/ _ \\ __|  |\n",
    "|  | |___ | ||  _/ ___ \\|  _ <_____| | |_| | | |_| | (_| | || (_| \\__ \\  __/ |_   |\n",
    "|   \\____|___|_|/_/   \\_\\_| \\_\\    |_|\\___/  |____/ \\__,_|\\__\\__,_|___/\\___|\\__|  |\n",
    "+---------------------------------------------------------------------------------+\n",
    "----------------------------------------------------------------------------------\n",
    "+---------------------------------------------+\n",
    "|   _   _                 _____ ___________   |\n",
    "|  | \\ | |               |_   _|_   _|  _  \\  |\n",
    "|  |  \\| | ___  _ __ ______| |   | | | | | |  |\n",
    "|  | . ` |/ _ \\| '_ \\______| |   | | | | | |  |\n",
    "|  | |\\  | (_) | | | |    _| |_ _| |_| |/ /   |\n",
    "|  \\_| \\_/\\___/|_| |_|    \\___/ \\___/|___/    |\n",
    "+---------------------------------------------+\n",
    "\"\"\"\n",
    "def non_iid_distribution_CIFAR(NUM_CLIENTS):\n",
    "    # Define the classes to include in each data loader\n",
    "    classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    model = CIFAR10_CNN()\n",
    "    model.to(device)\n",
    "    class_indices = []\n",
    "    client_map = dict()\n",
    "    for client in range(NUM_CLIENTS):\n",
    "        # Randomly select 2 classes for the client\n",
    "        class_indices.append(np.random.choice(classes, 2, replace=False))\n",
    "        \n",
    "        # Print the selected classes\n",
    "        print(f'Client {client}: {class_indices[client]}')\n",
    "\n",
    "    # Define the transform to apply to the dataset\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    # Load the CIFAR-10 dataset\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "    # Create a list to store the data loaders\n",
    "    train_data_loaders = []\n",
    "    test_data_loaders = []\n",
    "    # Create a data loader for each class combination\n",
    "    for indices in class_indices:\n",
    "        # Filter the dataset to include only the selected classes\n",
    "        filtered_trainset = torch.utils.data.Subset(trainset, [i for i in range(len(trainset)) if trainset.targets[i] in indices])\n",
    "        cli_train, cli_test = train_test_split(filtered_trainset, test_size=0.2)\n",
    "        cli_train_loader = torch.utils.data.DataLoader(cli_train, batch_size=32, shuffle=True, num_workers=2)\n",
    "        cli_test_loader = torch.utils.data.DataLoader(cli_test, batch_size=32, shuffle=True, num_workers=2)\n",
    "        train_data_loaders.append(cli_train_loader)\n",
    "        test_data_loaders.append(cli_test_loader)\n",
    "\n",
    "    for client in range(NUM_CLIENTS):\n",
    "        random_score = random.random()\n",
    "        client_map.update({client: [class_indices[client], train_data_loaders[client], test_data_loaders[client], model, [0.0], [random_score], random_score, 0]})\n",
    "    \n",
    "    return client_map\n",
    "\n",
    "\"\"\" \n",
    "+-----------------------+\n",
    "|   _____ ___________   |\n",
    "|  |_   _|_   _|  _  \\  |\n",
    "|    | |   | | | | | |  |\n",
    "|    | |   | | | | | |  |\n",
    "|   _| |_ _| |_| |/ /   |\n",
    "|   \\___/ \\___/|___/    |\n",
    "+-----------------------+\n",
    "\n",
    "\"\"\"\n",
    "def iid_distribution_CIFAR(NUM_CLIENTS):\n",
    "    placeholder = [-1, -1]\n",
    "    # Define the transform to apply to the dataset\n",
    "    client_map = dict()\n",
    "    model = CIFAR10_CNN()\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    # Load the CIFAR-10 dataset\n",
    "    trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "    # Split the dataset into 10 equal parts\n",
    "    trainsets = torch.utils.data.random_split(trainset, [int(len(trainset) / NUM_CLIENTS) for _ in range(NUM_CLIENTS)])\n",
    "\n",
    "    # Create a list to store the data loaders\n",
    "    train_data_loaders = []\n",
    "    test_data_loaders = []\n",
    "\n",
    "    for client in range(NUM_CLIENTS):\n",
    "        cli_train, cli_test = train_test_split(trainsets[client], test_size=0.2)\n",
    "        cli_train_loader = torch.utils.data.DataLoader(cli_train, batch_size=32, shuffle=True, num_workers=2)\n",
    "        cli_test_loader = torch.utils.data.DataLoader(cli_test, batch_size=32, shuffle=True, num_workers=2)\n",
    "        train_data_loaders.append(cli_train_loader)\n",
    "        test_data_loaders.append(cli_test_loader)\n",
    "    \n",
    "    for client in range(NUM_CLIENTS):\n",
    "        random_score = random.random()\n",
    "        client_map.update({client: [placeholder, train_data_loaders[client], test_data_loaders[client], model, [0.0], [random_score], random_score, 0]})\n",
    "    \n",
    "    return client_map\n",
    "\n",
    "\"\"\"\"\n",
    "+---------------------------------------------------------------------+\n",
    "|   __  __ _   _ ___ ____ _____   ____        _                 _     |\n",
    "|  |  \\/  | \\ | |_ _/ ___|_   _| |  _ \\  __ _| |_ __ _ ___  ___| |_   |\n",
    "|  | |\\/| |  \\| || |\\___ \\ | |   | | | |/ _` | __/ _` / __|/ _ \\ __|  |\n",
    "|  | |  | | |\\  || | ___) || |   | |_| | (_| | || (_| \\__ \\  __/ |_   |\n",
    "|  |_|  |_|_| \\_|___|____/ |_|   |____/ \\__,_|\\__\\__,_|___/\\___|\\__|  |\n",
    "+---------------------------------------------------------------------+\n",
    "\n",
    "+---------------------------------------------+\n",
    "|   _   _                 _____ ___________   |\n",
    "|  | \\ | |               |_   _|_   _|  _  \\  |\n",
    "|  |  \\| | ___  _ __ ______| |   | | | | | |  |\n",
    "|  | . ` |/ _ \\| '_ \\______| |   | | | | | |  |\n",
    "|  | |\\  | (_) | | | |    _| |_ _| |_| |/ /   |\n",
    "|  \\_| \\_/\\___/|_| |_|    \\___/ \\___/|___/    |\n",
    "+---------------------------------------------+\n",
    "\"\"\"\n",
    "def non_iid_distribution_MNIST(NUM_CLIENTS):\n",
    "    # Define the classes to include in each data loader\n",
    "    classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "    class_indices = []\n",
    "    client_map = dict()\n",
    "    model = MNIST_MLP()\n",
    "    for client in range(NUM_CLIENTS):\n",
    "        # Randomly select 2 classes for the client\n",
    "        class_indices.append(np.random.choice(classes, 2, replace=False))\n",
    "        \n",
    "        # Print the selected classes\n",
    "        print(f'Client {client}: {class_indices[client]}')\n",
    "\n",
    "    # Define the transform to apply to the dataset\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    # Load the MNIST dataset\n",
    "    trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "    # Create a list to store the data loaders\n",
    "    train_data_loaders = []\n",
    "    test_data_loaders = []\n",
    "    # Create a data loader for each class combination\n",
    "    for indices in class_indices:\n",
    "        # Filter the dataset to include only the selected classes\n",
    "        filtered_trainset = torch.utils.data.Subset(trainset, [i for i in range(len(trainset)) if trainset.targets[i] in indices])\n",
    "        cli_train, cli_test = train_test_split(filtered_trainset, test_size=0.2)\n",
    "        cli_train_loader = torch.utils.data.DataLoader(cli_train, batch_size=32, shuffle=True, num_workers=2)\n",
    "        cli_test_loader = torch.utils.data.DataLoader(cli_test, batch_size=32, shuffle=True, num_workers=2)\n",
    "        train_data_loaders.append(cli_train_loader)\n",
    "        test_data_loaders.append(cli_test_loader)\n",
    "\n",
    "    for client in range(NUM_CLIENTS):\n",
    "        random_score = random.random()\n",
    "        client_map.update({client: [class_indices[client], train_data_loaders[client], test_data_loaders[client], model, [0.0], [random_score], random_score, 0]})\n",
    "    \n",
    "    return client_map\n",
    "\n",
    "\"\"\"\n",
    "+-----------------------+\n",
    "|   _____ ___________   |\n",
    "|  |_   _|_   _|  _  \\  |\n",
    "|    | |   | | | | | |  |\n",
    "|    | |   | | | | | |  |\n",
    "|   _| |_ _| |_| |/ /   |\n",
    "|   \\___/ \\___/|___/    |\n",
    "+-----------------------+\n",
    "\"\"\"\n",
    "def iid_distribution_MNIST(NUM_CLIENTS):\n",
    "    placeholder = -1\n",
    "    # Define the transform to apply to the dataset\n",
    "    client_map = dict()\n",
    "    model = MNIST_MLP()\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    # Load the MNIST dataset\n",
    "    trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "    # Split the dataset into 10 equal parts\n",
    "    trainsets = torch.utils.data.random_split(trainset, [int(len(trainset) / NUM_CLIENTS) for _ in range(NUM_CLIENTS)])\n",
    "\n",
    "    # Create a list to store the data loaders\n",
    "    train_data_loaders = []\n",
    "    test_data_loaders = []\n",
    "\n",
    "    for client in range(NUM_CLIENTS):\n",
    "        cli_train, cli_test = train_test_split(trainsets[client], test_size=0.2)\n",
    "        cli_train_loader = torch.utils.data.DataLoader(cli_train, batch_size=32, shuffle=True, num_workers=2)\n",
    "        cli_test_loader = torch.utils.data.DataLoader(cli_test, batch_size=32, shuffle=True, num_workers=2)\n",
    "        train_data_loaders.append(cli_train_loader)\n",
    "        test_data_loaders.append(cli_test_loader)\n",
    "    \n",
    "    for client in range(NUM_CLIENTS):\n",
    "        random_score = random.random()\n",
    "        client_map.update({client: [placeholder, train_data_loaders[client], test_data_loaders[client], model, [0.0], [random_score], random_score, 0]})\n",
    "    \n",
    "    return client_map\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "+---------------------------------------------------------------------------+\n",
    "|   _   _                      _   _   _      _                      _      |\n",
    "|  | \\ | |                    | | | \\ | |    | |                    | |     |\n",
    "|  |  \\| | ___ _   _ _ __ __ _| | |  \\| | ___| |___      _____  _ __| | __  |\n",
    "|  | . ` |/ _ \\ | | | '__/ _` | | | . ` |/ _ \\ __\\ \\ /\\ / / _ \\| '__| |/ /  |\n",
    "|  | |\\  |  __/ |_| | | | (_| | | | |\\  |  __/ |_ \\ V  V / (_) | |  |   <   |\n",
    "|  \\_| \\_/\\___|\\__,_|_|  \\__,_|_| \\_| \\_/\\___|\\__| \\_/\\_/ \\___/|_|  |_|\\_\\  |\n",
    "+---------------------------------------------------------------------------+\n",
    "\"\"\"\n",
    "# ------------------------------------- MLP MNIST -------------------------------------\n",
    "class MNIST_MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNIST_MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28) # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "# ------------------------------------- CNN CIFAR-10 -------------------------------------\n",
    "class CIFAR10_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CIFAR10_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_clients(NUM_CLIENTS, dataset, distribution):\n",
    "    if dataset == 'MNIST':\n",
    "        if distribution == 'iid':\n",
    "            client_map = iid_distribution_MNIST(NUM_CLIENTS)\n",
    "        else:\n",
    "            client_map = non_iid_distribution_MNIST(NUM_CLIENTS)\n",
    "    else:\n",
    "        if distribution == 'iid':\n",
    "            client_map = iid_distribution_CIFAR(NUM_CLIENTS)\n",
    "        else:\n",
    "            client_map = non_iid_distribution_CIFAR(NUM_CLIENTS)\n",
    "    \n",
    "    return client_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The client map for the non-iid data distribution contains the following information associated with that client\n",
    "##### -Key: Client_Number | Values: Two_Classes, Training_Data, Testing_Data, Nueral_Network, Client Accuracies, Client Performance Scores, Current Performance Score\n",
    "\n",
    "#### The client map for the iid data distribution contains the following information associated with that client\n",
    "#####  -Key: Client_Number | Values: Placeholder, Training_Data, Testing_Data, Nueral_Network, Client Accuracies, Client Performance Scores,  Current Performance Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### The client map for the iid data distribution contains the following information associated with that client\n",
    "#####  -Key: Client_Number | Values: Placeholder, Training_Data, Testing_Data, Nueral_Network, Client Accuracies, Client Performance Scores, Current Performance Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "client_performance_score = dict()\n",
    "client_accuracies = dict()\n",
    "client_actual_score = dict()\n",
    "rounds = 10\n",
    "threshold = 0.8\n",
    "for client in range(NUM_CLIENTS):\n",
    "    random_score = random.random()\n",
    "    client_performance_score.update({client: [random_score]})\n",
    "    client_accuracies.update({client: [0.0]})\n",
    "    client_actual_score.update({client: 0.0}) \n",
    "\n",
    "for round in range(rounds):\n",
    "    for client in  range(NUM_CLIENTS):\n",
    "        random_num = random.random()*2\n",
    "        client_accuracies[client].append(random_num)\n",
    "        sel_client_acc = client_accuracies[client]\n",
    "        mean_score = sum(sel_client_acc) / len(sel_client_acc)\n",
    "        varience = sum([((x - mean_score) ** 2) for x in sel_client_acc]) / (len(sel_client_acc))\n",
    "        client_zero_score = client_actual_score[1]\n",
    "        if varience > threshold:\n",
    "            updated_score = client_performance_score[client][round] + 1.0\n",
    "            client_performance_score[client].append(updated_score)\n",
    "        else:\n",
    "            updated_score = client_performance_score[client][round]\n",
    "            client_performance_score[client].append(updated_score)\n",
    "        mean_performance_score = sum(client_performance_score[client]) / len(client_performance_score[client])\n",
    "        client_performance_score[client][round+1] = mean_performance_score\n",
    "        client_actual_score.update({client: [mean_performance_score]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_ages = dict()\n",
    "rounds = 100\n",
    "client_arr = []\n",
    "selected_clients = []\n",
    "clients_per_rnd = 10\n",
    "probability_of_comm = 0.8\n",
    "for i in range(NUM_CLIENTS):\n",
    "    client_arr.append(i)\n",
    "\n",
    "client_ages.update({9: 1})\n",
    "for client in range(NUM_CLIENTS-1):\n",
    "    client_ages.update({client: 0})\n",
    "\n",
    "for round in range(rounds):\n",
    "    sorted_clients = sorted(client_ages.items(), key=lambda x: x[1], reverse=True)\n",
    "    selected_clients = [x[0] for x in sorted_clients[:clients_per_rnd]]\n",
    "    for client in range(NUM_CLIENTS):\n",
    "        if client in selected_clients:\n",
    "            client_ages[client] = 0\n",
    "        else:\n",
    "            client_ages[client] = client_ages[client]**2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_client(client_map, selected_clients, local_epochs, learning_rate):\n",
    "    for client in selected_clients:\n",
    "        model = client_map[client][c.Model]\n",
    "        model.to(device)\n",
    "        train_loader = client_map[client][c.Training_Data]\n",
    "        test_loader = client_map[client][c.Testing_Data]\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "        for epoch in range(local_epochs):\n",
    "            running_loss = 0.0\n",
    "            for i, data in enumerate(train_loader, 0):\n",
    "                inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                if i % 2000 == 1999:\n",
    "                    print(f'Client: {client} Epoch: {epoch + 1}, Batch: {i + 1}, Loss: {running_loss / 2000}')\n",
    "                    running_loss = 0.0\n",
    "            \n",
    "        client_map[client][c.Model] = model\n",
    "    return client_map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
